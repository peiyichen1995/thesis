\chapter{Introduction}
\label{chap:Introduction}

The mathematically-consistent representation and identification of parametric uncertainties is a central task of uncertainty quantification (UQ) in computational mechanics. From a mechanics of materials standpoint \cite{GUILLEMINOT2020385}, such fluctuations can be primarily attributed to subscale variability, which itself---and most often---stems from complex processing conditions for engineered composites (such as fiber-reinforced composites or concrete), or evolution-based optimization in the case of biological tissues. There has been a tremendous amount of works focusing on the integration of such uncertainties in the past three decades. Labeled statistical distributions, such as Gaussian, Gamma, and lognormal distributions, are generally assumed to model homogeneous stochastic inputs. The choice of these distributions is sometimes arbitrarily made or based on data fitting (which may lead to ill-posed forward problems), and can facilitate uncertainty propagation through spectral approaches \cite{Ghanem1991, OLM, Ghanem2017} where quantities of interest are represented by polynomial chaos surrogate models \cite{Wiener,Cameron,Xiu2002,Soize2004}. When an accurate microstructural description is not possible, due to data limitation, prior models can be constructed that capture available physical information, such as anisotropy, as well as mathematical constraints related to well-posedness for the associated forward propagation problem. Information-theoretic contributions proceeding along those lines can be found in \cite{Soize2006,Guilleminot-IJNME-2017,Guilleminot-SIAM-2013,STABER2017399} for the case of tensor-valued coefficients in linear differential operators, to list a few; see also \cite{Grigoriu2016} for yet another type of methodology, as well as \cite{SOIZE2011} for integration within a Bayesian setting.

While traditional approaches have established a solid foundation for uncertainty quantification in computational mechanics, the complex nature of certain materials demands more adaptive and data-driven approaches. Lately, constitutive models based on neural networks (NN) have also received growing attention over the past few years, owing to their ability to represent nonlinear mappings in a high dimensional setting. There is a very substantial amount of papers published on this topic, for a wide variety of material behaviors; see, \textit{e.g.},  \cite{flaschel2021unsupervised,xu2021learning,holzapfel2021predictive,jung2006neural,ghaboussi1998autoprogressive,ghaboussi1998new,hashash2004numerical,furukawa1998implicit,joshi2022bayesian,as2022mechanics,Asad-IJNME,KLEIN2022104703} and the references therein, in a non-exhaustive manner. Beyond classical data science aspects that pertain to architecture design, training and validation strategies, and the analysis of approximation capabilities, a central concern is to make such surrogates amenable to scientific simulations where such models are typically set to parameterize systems of partial differential equations. In this context, the surrogate must satisfy both physical assumptions and mathematical properties (\textit{e.g.}, boundedness or a certain type of convexity) to ensure the existence (and potentially, the uniqueness) of solutions. From the interests of mathematically-consistent representations, where precision and robustness are significant, we know that a high-fidelity simulation, oftentimes in the form of coupled partial differential equations (PDEs), is computationally prohibitive as a feasible forward simulation within the outer loop in many decision-making applications, e.g. inverse problem, optimal control, uncertainty quantification, etc. To avoid evaluating the expensive high-fidelity model in a forward simulation, a reduced order model (ROM) can be trained as its surrogate with reasonable accuracy, hence significantly reducing the computational cost allowing for faster simulations and real-time applications without sacrificing the essence of the underlying mathematical principles. Nonlinear PDEs describe a wide spectrum of engineering problems. High-fidelity numerical solvers based on high-dimensional spatial discretizations are prohibitively expensive in many-query settings. Intrusive and non-intrusive LS-ROMs reduce the dimensionality of the model by projecting the solution of the high-dimensional model onto a linear subspace. Several approaches to defining the approximation subspace have been proposed (see e.g. \cite{benner2015survey} for a review). A common empirical choice is the proper orthogonal decomposition (POD) subspace, which spans the leading principal components of an available set of state data \cite{berkooz1993proper,lumley1967structure,sirovich1987turbulence}. For PDEs with only linear and polynomial terms, the projection-based reduced model admits an efficient low-dimensional numerical representation that can be cheaply evaluated at a cost independent of the dimension of the original model \cite{benner2015two,benner2015survey,cuong2005certified,goyal2016algebraic,hesthaven2016certified}. For PDEs with more general nonlinear terms, an additional level of approximation, e.g., interpolation \cite{astrid2008missing,barrault2004empirical,carlberg2013gnat,chaturantabut2010nonlinear,drmac2016new,grepl2007efficient,nguyen2008best}, is generally needed to achieve computational efficiency. Alternatively, the works in \cite{benner2015two,goyal2016algebraic,kramer2019nonlinear,kramer2019balanced} transform PDEs with general nonlinear terms to representations with only quadratic nonlinearities via the use of structure-exposing lifting transformations, and then project the quadratic operators of the resultant lifted PDE to obtain a reduced model. In recent years, machine learning based approaches to NM-ROMs have received an increasing interest. Some treat the weights and biases of a deep neural network (DNN) as unknowns in the solution process \cite{dissanayake1994neural,lagaris1998artificial,meade1994numerical,van1995neural}, while others incorporate physical laws into DNN-based surrogates whose weights and biases are determined in the training phase \cite{han2018solving,lu2019deeponet,lu2021deepxde,pang2019fpinns,raissi2019physics,lee2020model,lee2019deep}. 

Notet that uncertainties within nonlinear constitutive models can be defined in a multiscale framework where material parameters are made random. Concurrent nonlinear simulations involve the strong coupling between a macroscopic (or structural) formulation and a microscopic description capturing subscale details \cite{ghosh1996two,smit1998prediction,feyel1999multiscale,feyel2000fe2,terada2001class,kouznetsova2002multi,geers2016multiscale,raju2021review}. One popular approach is the so-called FE$^2$ method \cite{feyel1999multiscale,feyel2000fe2}, where information (in the form of a deformation gradient and any adapted stress variable) is transferred back-and-forth between quadrature points at the macroscale and statistical or representative volume elements (depending on whether the separation of scales exists or not). While versatile and powerful, such frameworks require significant computational resources that often surpass the capabilities of intermediate-power computers, especially when the underlying behavior is highly nonlinear. In this context, the development of surrogate models for large-scale systems has become a very active research domain and has generated a substantial body of literature. Various methodologies have been proposed to address this challenge, including (in a non-exhaustive manner) the development of deterministic representations \cite{yvonnet2007reduced,monteiro2008computational,yvonnet2009numerically, temizer2007adaptive,temizer2007numerical,fritzen2013reduced,bhattacharjee2016nonlinear, yvonnet2013computational,fritzen2018two,liu2016self,han2020efficient,feng2021concurrent} and probabilistic/statistical-based approaches \cite{efendiev2004multiscale,efendiev2009multiscale,weinan2003heterognous,weinan2007heterogeneous,abdulle2013adaptive,abdulle2012heterogeneous}, and more recently, the integration of machine learning (ML) tools, both with and without probabilistic/statistical formulations; see, e.g., \cite{le2015computational,rao2020three,lu2019data,leung2022nh,nguyen2019surrogate,minh2020surrogate,feng2022finite,han2023neural,wessels2022computational,black2023deep}. In most of the above contributions, the multiscale surrogate is built either through polynomial approximations or deep learning models, and applied \textit{locally} at each point of the coarse scale discretization. In these settings, the intrinsic randomness --- and potential non-locality --- induced by random media with non-separated scales is very challenging to capture due to representation limitations.

The goal of this thesis lies in the construction of mathematically-consistent representation for deep learning methods and uncertainty quatification in computational mechanics. We consider the class of hyperelastic models with a specific interest in soft biological tissues characterized by extensive variability attributed to factors like age, gender, health conditions and microstructural complexity. Uncertainties raised by these factors make it chanllenging to applications such as computer-assisted diagnostics and surgical procedures or the growth of compatible artificial substitutes.

\section{Research Contributions}

\begin{itemize}
    \item[1.] We develop a stochastic model for the spatially-dependent material parameters parameterizing anisotropic strain energy density functions. The construction is cast within the framework of information theory, which is invoked to derive a least-informative model while ensuring consistency with theoretical requirements in finite elasticity. Specifically, almost sure polyconvexity and uniform growth conditions are enforced through proper repulsion constraints and regularization, hence making the forward problem of uncertainty propagation well posed. In addition, transformations arising from the linearization procedure are introduced for consistency and induce statistical dependencies in the primary variables. The latter include material moduli, a weight balancing between the isotropic and anisotropic contributions, and the angle defining the structural tensors. The identification of the model is subsequently performed, using an existing database on human arterial walls. Maximum likelihood estimators are obtained and provided for the adventitia, media, and intima layers, which enables the use of the proposed model as a generative surrogate for, e.g., training and classification in data-driven approaches integrating inter-patient variability. Finally, uncertainty propagation on a realistic, patient-specific geometry is conducted to demonstrate the efficiency of the stochastic modeling framework.
    \item[2.] We propose a simple approach to rectify unconstrained neural networks for hyperelastic constitutive models with the aim of ensuring both mathematical well-posedness (in terms of existence theorems) and physical consistency. The surrogate involves neural networks that are made admissible by selecting a proper parameterization, following standard results in continuum mechanics, and by enforcing polyconvexity through integral representations. We also demonstrate the relevance of the formulation by considering digitally synthesized and experimental datasets for isotropic and anisotropic materials, including the case of soft biological tissues.
    \item[3.] We develop a nonlinear manifold reduced order model (NM-ROM) based on Convolutional Neural Network-based autoencoders (CNNAE) with iteration-dependent trainable kernels inspired from adpative basis methods. We investigate DNN-based operator inference strategies between latent spaces, and propose a strategy to perform vectorized implicit time integration. We demonstrate that the proposed CNN-based NM-ROM, combined with DNN-based operator inference, generally performs better than commonly employed strategies (in terms of prediction accuracy) on a benchmark advection-dominated problem. The method also presents substantial gain in terms of training speed per epoch, with a training time about one order of magnitude smaller than the one associated with a state-of-the-art technique performing with the same level of accuracy.
    \item[4.] We present a methodology that addresses the construction of statistical surrogates for concurrent multiscale modeling in structures comprising nonlinear random materials from the point of view of probabilistic learning. More specifically, we formulate the approximation problem using conditional statistics, and use probabilistic learning on manifolds to draw samples of the nonlinear constitutive model at mesoscale accelerating multiscale computations bypass solving the nonlinear boundary problems at the mesocopic scale. Two applications, relevant to inverse problem solving and forward propagation, are presented in the context of nonlinear elasticity. The framework enables accurate predictions (in probability law), despite the small amount of training data and the very high levels of nonlinearity and stochasticity in the considered system.
\end{itemize}

\section{Organization of the dissertation}

In Chapter~\ref{chap:artery}, we revisit and extend the methodological steps presented in \cite{STABER201894} to model spatially-varying stochastic anisotropic strain energy density functions. The regularization is imposed on the isotropic part of the strain energy density function and the parameterization is extended to account for fluctuations and waviness in the structural tensors and covariance kernel. We also address the identification of the model based on experimental results available on human arterial walls, with the goal of providing interested readers with the capability to generate datasets that are consistent with inter-patient fluctuations. In Chapter~\ref{chap:polyconvex}, we construct a convex neural network model without affecting expressiveness (that is, without constraining weights \textit{a priori}) and training cost (which can be affected by transformations performed on weights at the training stage). The rectified neural network models is then deployed on digitally synthesized and experimental datasets, relevant to both isotropic and anisotropic materials. In Chapter~\ref{chap:cnnae}, we devise a novel structure for the decoder in the NM-ROM, such that the underlying nonlinear mapping closely resembles the formulation of adaptive basis methods. We also propose a DNN-based reduced operator inference that learns from the latent space for full models based on time-dependent partial differential equations. In Chapter~\ref{chap:fe2}, we introduce a statistical surrogate model for concurrent multiscale simulations involving nonlinear materials with non-separated scales. The methodology combines probabilistic learning on manifolds, a generative model that allows for measure concentration and support information to be accurately captured, with the use of conditional statistics to approximate the mapping between apparent strain and stress variables --- namely, the right Cauchy-Green tensor and the second Piola-Kirchhoff stress tensor --- at a finite set of points (defining a subregion of interest where concurrent coupling must be deployed). In the Section~\ref{sec:intro-background}, we'll briefly recall the framework of continuum mechanics of hyperelastic materials that will be used in this work.

\section{Notation}

\noindent (i) {\textit{Conventions for variables}}.\\
A lower-case Latin or Greek letter, such as $x$ or $\eta$, is a deterministic real variable.\\
A boldface lower-case Latin or Greek letter, such as $\bfx$ or $\bfeta$, is a deterministic vector.\\
An upper-case Latin or Greek letter, such as $X$ or $\Xi$, is a real-valued random variable.\\
A boldface upper-case Latin letter, such as $\bfX$, is a vector-valued random variable.\\
A lower- or upper-case Latin letter between brackets, such as $[x]$ or $[X]$, is a deterministic matrix.\\
A boldface upper-case letter between brackets, such as $[\bfX]$, is a matrix-valued random variable.\\

\noindent (ii) {\textit{Probability space, random variable, probability measure, and probability density function.}}\\
For any finite integer $m\geq 1$, the Euclidean space $\RR^m$ is equipped with the $\sigma$-algebra $\curB_{\RR^m}$.
If $\bfY$ is a $\RR^m$-valued random variable defined on the probability space $(\Theta,\curT,\curP)$, $\bfY$ is a  mapping $\theta\mapsto\bfY(\theta)$ from $\Theta$ into $\RR^m$, measurable from $(\Theta,\curT)$ into $(\RR^m,\curB_{\RR^m})$,
and $\bfY(\theta)$ is a realization (sample) of $\bfY$ for $\theta\in\Theta$. 
The probability distribution of $\bfY$ is the probability measure $P_{\bfY}(d\bfy)$ on the measurable set $(\RR^m,\curB_{\RR^m})$ (we will simply say on $\RR^m$). 
The Lebesgue measure on $\RR^m$ is denoted by $d\bfy$ and $P_{\bfY}(d\bfy) = p_{\bfY}(\bfy)\, d\bfy$, with $p_{\bfY}$ the probability density function (pdf) on $\RR^m$ of $P_{\bfY}(d\bfy)$ with respect to $d\bfy$.
Finally, $E$ denotes the mathematical expectation operator.\\

\noindent (iii) {\textit{Algebraic notations}}.\\
$\RR$: set of all the real numbers.\\
$\RR^n$: Euclidean vector space on $\RR$ of dimension $n$.\\
$\MM_{n,m}$: set of all the $(n\times m)$ real matrices.\\
$\MM_n$: set of all the square $(n\times n)$ real matrices.\\
$\MM_n^+$: set of all the positive-definite symmetric $(n\times n)$ real matrices.\\
$[I_{n}]$: identity matrix in $\MM_n$.\\
$\bfx = (x_1,\ldots,x_n)$: point in $\RR^n$.\\
$\langle \bfx,\bfy \rangle = x_1 y_1 + \ldots + x_n y_n$: inner product in $\RR^n$.\\
$\Vert\,\bfx\,\Vert$:  norm in $\RR^n$ such that $\Vert\,\bfx\,\Vert = \langle \bfx,\bfx \rangle$.\\
$[x]^T$: transpose of matrix $[x]$.\\
$\Vert\, [x]\, \Vert$: Frobenius norm of matrix  $[x]$.\\
$\delta_{kk'}$: Kronecker's symbol.

\section{Background}
\label{sec:intro-background}
\subsection{Constitutive Modeling for Arterial Tissues}
\label{subsubsec:constitutive-modeling}
Let $B$ be a collection of material points identified with their vector of coordinates $\bfx$ in $\mathbb{R}^3$, and denote by $\partial B$ the boundary of $B$. For any material point $\bfx \in B$, the spatial point $\bfx_\varphi$ in the deformed configuration $B_\varphi$ is given by $\bfx_\varphi = \varphi (\bfx)$, where $\varphi$ is the deformation map. For any $\bfx \in B$, the deformation gradient $\bfF$ is a second-order tensor defined as $\bfF = \boldsymbol{\nabla}_{\bfx} \bfx_\varphi$. The right Cauchy-Green deformation tensor is defined as $\bfC = \bfF^T \bfF$. For later use, we introduce the isochoric counterpart $\overline{\bfC}$ of $\bfC$, defined as $\overline{\bfC} = J^{-2/3}\bfC$, with $J = \det(\bfF)$ the Jacobian of the transformation. Notice that notations $\bfx$ and $\bfx_\varphi$ to denote points in the reference and deformed configurations, respectively, is unusual in the literature of finite elasticity \cite{Ciarlet1988} but is introduced for the sake of consistency with the rest of this paper---where deterministic vector-valued variables are represented with bold lowercase symbols.

Following standard assumptions \cite{Holzapfel2000,Gasser2006,Holzapfel2010,Holzapfel2015,Holzapfel2017} (see also \cite{Brinkhues2013ModelingAS} and the references therein for instance), the material is assumed to be hyperelastic, nearly-incompressible, and anisotropic. Note that while a transversely isotropic model is considered hereinafter, due to the considered application, the methodological ingredients related to the construction of the stochastic model remain valid for other classes of anisotropy. The nonlinear constitutive model is thus defined by a strain energy density function $\psi:\mathbb{M}^3_+ \to \mathbb{R}$ taken as
\begin{align}
    \psi(\bfF) = \psi^{\text{MR}}(\bfF) + \psi^\text{p}(\bfF) + \sum_{k=1}^{2} \psi_{(k)}^\text{ti}(\bfF)\,, \label{eq: strain energy density function}
\end{align}
in which $\psi^{\text{MR}}$ denotes an isochoric Mooney-Rivlin strain energy density function, $\psi^\text{p}$ is a penalty term used to account for the near-incompressibility constraint \cite{charrier1988existence}, and $\{\psi_{(k)}^\text{ti}\}_{k = 1}^2$ are anisotropic strain energy density functions to be defined momentarily. The Mooney-Rivlin contribution is given by
\begin{align}
    \psi^{\text{MR}}(\bfF) &= \mu_1 \left( \textnormal{tr}(\overline{\bfC}) - 3 \right) + \mu_2 \left( \textnormal{tr}(\text{Cof}(\overline{\bfC}))^{3/2} - 3^{3/2}\right) \label{eq: MR} 
\end{align}
with a slight abuse of notation, where $\mu_1$ and $\mu_2$ are strictly positive material parameters, ``$\textnormal{tr}$'' denotes the trace operator and ``$\text{Cof}$'' is the matrix of cofactors, $\text{Cof}(\overline{\bfA}) = \det(\bfA)\bfA^{-T}$ for any matrix $\bfA$. The penalty term is given by
\begin{align}
    \psi^\text{p}(\bfF) & = \mu_3 (J^{\beta_3}+J^{-\beta_3} - 2)\,, \label{eq: penalty}
\end{align}
where $\mu_3 \in \mathbb{R}_{> 0}$ and $\beta_3 \in \mathbb{R}_{> 2}$ are viewed as numerical model parameters. The anisotropic contribution modeling the stiffening effect of the tissue in tension (only), along a direction defined by a unit vector $\bfa^{(k)}$, is defined as
\begin{equation}
    \psi_{(k)}^\text{ti}(\bfF) = \frac{\mu_4}{\beta_4} \left\{ \exp \left(\beta_4 \left( (1-\rho)(\textnormal{tr}(\bfC)-3)^2 + \rho (\vert \vert \bfF \bfa^{(k)} \vert \vert ^2_2 - 1)^2 \right) \right) - 1\right\}\,, \label{eq: psi tissue-artery}
\end{equation}
where $\mu_4 \in \mathbb{R}_{> 0}$, $\beta_4 \in \mathbb{R}_{> 0}$, and $\rho \in [0,1]$ are material parameters \cite{holzapfel2005determination}. Following standard modeling assumptions, the unit vectors $\bfa^{(1)}$ and $\bfa^{(2)}$ are defined as
\begin{equation}    
    \bfa^{(1)} = \cos(\alpha) \bfe^{(1)} + \sin(\alpha)\bfe^{(2)}\,, \quad 
    \bfa^{(2)} = \cos(\alpha) \bfe^{(1)} - \sin(\alpha)\bfe^{(2)}\,,
\end{equation}
where $\bfe^{(1)}$ and $\bfe^{(2)}$ are unit vectors defining a local basis at every location $\bfx$ in the reference configuration, and $\alpha$ is the angle between tissue orientation and the aforementioned basis. Notice that $\psi_{(1)}^\text{ti} = \psi_{(2)}^\text{ti}$ in this case, owing to the evenness of the right-hand side in Eq.~\eqref{eq: psi tissue-artery}.

\begin{prop}
The stored energy density function $\psi$ defined by Eq.~\eqref{eq: strain energy density function} is polyconvex and satisfies proper growth conditions, hence ensuring the well-posedness of the nonlinear boundary value problem \cite{Ciarlet1988,ball2002some}.
\end{prop}

\begin{proof} 
The strain energy density function $\bfF \mapsto \psi(\bfF)$ is polyconvex if and only if there exists a convex function $\psi^*$ such that
\begin{align}
    \psi(\bfF) & = \psi^*(\bfF, \text{Cof}(\bfF), \det(\bfF))
\end{align}
for all $\bfF$ in $\mathbb{M}^3$. For an additive decomposition, the above requirement amounts to showing that each term in $\psi$ is a convex function in the associated variable. For the isotropic contribution, the convexity of the functions $\bfF \mapsto \textnormal{tr}(\overline{\bfC}) = \vert \vert \bfF \vert \vert_F^2/(\det(\bfF))^{2/3}$ and $\bfF \mapsto \textnormal{tr}(\text{Cof}(\overline{\bfC}))^{3/2} = \vert \vert \text{Cof}(\bfF) \vert \vert_F^3/(\det(\bfF))^2$ was established in many references; see, e.g., \cite{hartmann2003polyconvexity,schroder2003invariant}. Regarding the anisotropic counterpart, notice first that the convexity of the function $\bfF \mapsto \langle \vert \vert \bfF \bfa_k \vert \vert ^2-1 \rangle^2_m$ was shown in \cite{balzani2006polyconvex}. Since the function $\bfF \mapsto \textnormal{tr}(\bfC)$ is convex, it then follows that the convex combination $(1-\rho)(\textnormal{tr}(\bfC)-3)^2 + \rho \langle \vert \vert \bfF \bfa_k \vert \vert ^2-1 \rangle^2_m$, with $\rho \geq 0$,  also defines a convex function in $\bfF$. For $\beta_4 > 0$, the exponential term in Eq.~\eqref{eq: psi tissue-artery} is thus the composition of a (strictly) convex nondecreasing function and a convex function, and is therefore convex. For $\mu_4 > 0$, the strain energy density function defined is hence polyconvex. For growth conditions, see, e.g., \cite{ball2002some}.
\end{proof}

\subsection{Definition of the Boundary Value Problem}\label{subsec:def-NBVP}

In a general setting, the strong form of the boundary value problem (balance of linear momentum) in the reference configuration is stated as \cite{wriggers2008nonlinear}
\begin{align}
    \boldsymbol{\nabla}_{\bfx} \bf{P} + \bf{b}  = {\bf{0}}\,,& \quad \forall\,\bfx \in {B}\,, \label{eq: stress divergence}\\
    \bfu = \overline{\bfu}\,,& \quad \forall\, \bfx \in \partial B_D\,,\\
    \bfP \cdot \bfN = \overline{\bft}\,,& \quad \forall\, \bfx \in \partial B_N\,,
\end{align}
where $\boldsymbol{\nabla}_{\bfx}$ denotes the divergence operator in the reference configuration, $\bfP$ is the first Piola-Kirchhoff stress tensor defined as
\begin{equation}
    \bfP = \displaystyle{\frac{\partial w(\bfF)}{\partial \bfF}}\,,
\end{equation}
the vector $\bfb$ is the body force, $\bfN$ is unit vector normal to the boundary in the reference configuration, $\overline{\bfu}$ and $\overline{\bft}$ are given smooth vector fields on the Dirichlet and Neumann boundaries, denoted by $\partial B_D$ and $\partial B_N$ respectively. The solution to the above problem is classically sought (in an appropriate function space) as a stationary point of the following energy functional \cite{wriggers2008nonlinear}:
\begin{align}
    \Pi(\varphi) &= \int_B \psi(\bfF) \, dV - \int_{B} \bfb \cdot \varphi\,dV - \int_{\partial B_N} \overline{\bft} \cdot \varphi\,dA\,.
\end{align}